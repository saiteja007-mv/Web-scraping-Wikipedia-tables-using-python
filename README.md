Web Scraping

In this repo I used wikipedia website to scrap tables

-------Steps for extraction--------
1.Go to any wikipedia page which has tables (https://en.wikipedia.org/wiki/List_of_districts_of_Puducherry)
    ![tableforgit](https://user-images.githubusercontent.com/56865372/205826411-37eae1f5-a69b-468f-ab49-a39379ef4f9b.png)
    
2.Select any element in table 
    ![select_table](https://user-images.githubusercontent.com/56865372/205826988-645f0df2-ece2-4a49-9b66-eda9279c2227.png)

3.After click inspect option and locate the table tag, find class attribute in that table tag
    ![inspect_table](https://user-images.githubusercontent.com/56865372/205829100-744eed2f-4867-4067-ab9a-eac107f985d2.png)

4.Copy that class attribute value paste it in 2nd cell of code (jupyter notebook)
    ![code_notebook](https://user-images.githubusercontent.com/56865372/205829685-118c7344-f279-4729-abd9-ba1ff371a2c8.png)

5.And also replace the URL variable with your required URL
    ![link_notebook](https://user-images.githubusercontent.com/56865372/205830497-d489fe30-d480-4d06-bc1e-a8e242e46405.png)

6.Another important thing is that put the file as you required and in required folder which is in last cell of notebook
    ![new_file_note](https://user-images.githubusercontent.com/56865372/205833803-7a7ec94c-e64d-441a-b023-1273eac430c7.png)

    

Now you will get the required table in CSV format 
    
    
